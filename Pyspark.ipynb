{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJpsRYk6LJApZVfyFRaoqJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DevD000/hexaware_training_2/blob/main/Pyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bDzrkXAl5kK",
        "outputId": "63c001c7-862e-4773-99a9-bfb1db4048fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=202a489662f6fc819f8934d43133bb26e3f467fcc80a401948017faeb4748365\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import PySpark and initialize a Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PySpark Notebook Example\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Verify the Spark session is working\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "EJqyoudhm--f",
        "outputId": "56f495a2-074b-4b07-c562-70d474ec78ff"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x78b1e2bbf850>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://2a05b60bb03f:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySpark DataFrame Example</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PySpark DataFrame Example\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Sample data representing employees\n",
        "data = [\n",
        "    (\"John Doe\", \"Engineering\", 75000),\n",
        "    (\"Jane Smith\", \"Marketing\", 60000),\n",
        "    (\"Sam Brown\", \"Engineering\", 80000),\n",
        "    (\"Emily Davis\", \"HR\", 50000),\n",
        "    (\"Michael Johnson\", \"Marketing\", 70000),\n",
        "]\n",
        "\n",
        "# Define schema for DataFrame\n",
        "columns = [\"Name\", \"Department\", \"Salary\"]\n",
        "\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(data, schema=columns)\n",
        "\n",
        "# Show the DataFrame\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11uyVkIPnXe6",
        "outputId": "7257f827-7c4a-4284-9353-e32b98d07021"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-----------+------+\n",
            "|           Name| Department|Salary|\n",
            "+---------------+-----------+------+\n",
            "|       John Doe|Engineering| 75000|\n",
            "|     Jane Smith|  Marketing| 60000|\n",
            "|      Sam Brown|Engineering| 80000|\n",
            "|    Emily Davis|         HR| 50000|\n",
            "|Michael Johnson|  Marketing| 70000|\n",
            "+---------------+-----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "high_salary_df=df.filter(col(\"Salary\")>65000)\n",
        "print(\"employees with salary >65000\")\n",
        "high_salary_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zQ_vvVRqSWt",
        "outputId": "7b2c15e7-f895-4b8e-85a5-5691ed115b21"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "employees with salary >65000\n",
            "+---------------+-----------+------+\n",
            "|           Name| Department|Salary|\n",
            "+---------------+-----------+------+\n",
            "|       John Doe|Engineering| 75000|\n",
            "|      Sam Brown|Engineering| 80000|\n",
            "|Michael Johnson|  Marketing| 70000|\n",
            "+---------------+-----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql. functions import col\n",
        " # Initialize SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Customer Transaction Analysis\") \\\n",
        "    .getOrCreate()\n",
        " # sample data for customers\n",
        "customers= [\n",
        "  (1,  \"Ravi \" ,\"Mumbai \"),\n",
        "  (2, \"Priya\" ,  \"Delhi\"),\n",
        "  (3, \"Vijay\", \"Bangalore\"),\n",
        "  (4, \"Anita \" , \" Chennai \"),\n",
        "  (5,\"Raj\",\"Hyderabad\" ), ]\n",
        "\n",
        "\n",
        " # Sample data for transactions\n",
        "transactions = [\n",
        " (1, 1, 10000.50),\n",
        " (2, 2, 20000.75 ),\n",
        " (3, 1, 15000.25 ),\n",
        " (4, 3, 30000.00 ),\n",
        " (5, 2 ,40000.50 ),\n",
        " (6, 4 ,25000.00 ),\n",
        " (7, 5, 18000.75 ),\n",
        " (8, 1, 5000.00)]\n",
        "\n",
        "# Define schema for DataFrames\n",
        "\n",
        "customer_columns = [\"Customer ID\", \"Name\", \"City\" ]\n",
        "transaction_columns = [\"Transaction1D\", \"Customer ID\", \"Amount\" ]\n",
        "# create DataFrames\n",
        "\n",
        "customer_df = spark . createDataFrame (customers, schema=customer_columns)\n",
        "transaction_df = spark. createDataFrame (transactions, schema=transaction_columns)\n",
        "\n",
        "# Show the Datauames\n",
        "print (\"Customers DataFrame : \")\n",
        "customer_df. show ( )\n",
        "print (\"Transactions DataFrame : \")\n",
        "transaction_df . show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzIkmi2GDlyU",
        "outputId": "a98b00a2-841c-47d2-e337-b43b4c3de741"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customers DataFrame : \n",
            "+-----------+------+---------+\n",
            "|Customer ID|  Name|     City|\n",
            "+-----------+------+---------+\n",
            "|          1| Ravi |  Mumbai |\n",
            "|          2| Priya|    Delhi|\n",
            "|          3| Vijay|Bangalore|\n",
            "|          4|Anita | Chennai |\n",
            "|          5|   Raj|Hyderabad|\n",
            "+-----------+------+---------+\n",
            "\n",
            "Transactions DataFrame : \n",
            "+-------------+-----------+--------+\n",
            "|Transaction1D|Customer ID|  Amount|\n",
            "+-------------+-----------+--------+\n",
            "|            1|          1| 10000.5|\n",
            "|            2|          2|20000.75|\n",
            "|            3|          1|15000.25|\n",
            "|            4|          3| 30000.0|\n",
            "|            5|          2| 40000.5|\n",
            "|            6|          4| 25000.0|\n",
            "|            7|          5|18000.75|\n",
            "|            8|          1|  5000.0|\n",
            "+-------------+-----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Join the DataFrames on Customer ID\n",
        "customer_transactions_df = customer_df . join (transaction_df,  on =\"Customer ID\" )\n",
        "\n",
        "print (\"customer Transactions DataFrame:\" )\n",
        "customer_transactions_df . show ( )\n",
        "\n",
        "# calculate the total amount spent by each customer\n",
        "total_spent_df = customer_transactions_df.groupBy( \"Name\").sum( \"Amount\").withColumnRenamed(\"sum(Amount)\",\n",
        "\"Total spent\" )\n",
        "print (\"Total Amount spent by Each customer : \")\n",
        "\n",
        "\n",
        "total_spent_df.show()\n",
        "\n",
        "# # Find customers who have spent more than\n",
        "big_spenders_df = total_spent_df . filter (col(\"Total spent\" )> 30000)\n",
        "print (\n",
        "\"Customers Who Spent More Than ? 30, 000: \" )\n",
        "big_spenders_df . show ( )\n",
        "\n",
        "\n",
        "# # Count the number of transactions per customer\n",
        "transactions_count_df = customer_transactions_df . groupBy (\"Name\").count().withColumnRenamed ( \"count \" , \"Transactioncount \")\n",
        "print ( \"Number of Transactions per customer : \")\n",
        "transactions_count_df. show ()\n",
        "\n",
        "# # sort customers by total amount spent in descending order\n",
        "sorted_spenders_df = total_spent_df. orderBy (col (\"Total spent\") .desc() )\n",
        "print (\"Customers sorted by Total spent (Descending) : \")\n",
        "sorted_spenders_df. show ()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efG3wyB3MegQ",
        "outputId": "0a3dda60-8d99-4340-ac0d-89ab17d49962"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "customer Transactions DataFrame:\n",
            "+-----------+------+---------+-------------+--------+\n",
            "|Customer ID|  Name|     City|Transaction1D|  Amount|\n",
            "+-----------+------+---------+-------------+--------+\n",
            "|          1| Ravi |  Mumbai |            1| 10000.5|\n",
            "|          1| Ravi |  Mumbai |            3|15000.25|\n",
            "|          1| Ravi |  Mumbai |            8|  5000.0|\n",
            "|          2| Priya|    Delhi|            2|20000.75|\n",
            "|          2| Priya|    Delhi|            5| 40000.5|\n",
            "|          3| Vijay|Bangalore|            4| 30000.0|\n",
            "|          4|Anita | Chennai |            6| 25000.0|\n",
            "|          5|   Raj|Hyderabad|            7|18000.75|\n",
            "+-----------+------+---------+-------------+--------+\n",
            "\n",
            "Total Amount spent by Each customer : \n",
            "+------+-----------+\n",
            "|  Name|Total spent|\n",
            "+------+-----------+\n",
            "|Anita |    25000.0|\n",
            "| Ravi |   30000.75|\n",
            "| Priya|   60001.25|\n",
            "| Vijay|    30000.0|\n",
            "|   Raj|   18000.75|\n",
            "+------+-----------+\n",
            "\n",
            "Customers Who Spent More Than ? 30, 000: \n",
            "+-----+-----------+\n",
            "| Name|Total spent|\n",
            "+-----+-----------+\n",
            "|Ravi |   30000.75|\n",
            "|Priya|   60001.25|\n",
            "+-----+-----------+\n",
            "\n",
            "Number of Transactions per customer : \n",
            "+------+-----+\n",
            "|  Name|count|\n",
            "+------+-----+\n",
            "|Anita |    1|\n",
            "| Ravi |    3|\n",
            "| Priya|    2|\n",
            "| Vijay|    1|\n",
            "|   Raj|    1|\n",
            "+------+-----+\n",
            "\n",
            "Customers sorted by Total spent (Descending) : \n",
            "+------+-----------+\n",
            "|  Name|Total spent|\n",
            "+------+-----------+\n",
            "| Priya|   60001.25|\n",
            "| Ravi |   30000.75|\n",
            "| Vijay|    30000.0|\n",
            "|Anita |    25000.0|\n",
            "|   Raj|   18000.75|\n",
            "+------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Product Sales Analysis\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Sample data for products\n",
        "products = [\n",
        "    (1, \"Laptop\", \"Electronics\", 50000),\n",
        "    (2, \"Smartphone\", \"Electronics\", 30000),\n",
        "    (3, \"Table\", \"Furniture\", 15000),\n",
        "    (4, \"Chair\", \"Furniture\", 5000),\n",
        "    (5, \"Headphones\", \"Electronics\", 2000),\n",
        "]\n",
        "\n",
        "# Sample data for sales transactions\n",
        "sales = [\n",
        "    (1, 1, 2),\n",
        "    (2, 2, 1),\n",
        "    (3, 3, 3),\n",
        "    (4, 1, 1),\n",
        "    (5, 4, 5),\n",
        "    (6, 2, 2),\n",
        "    (7, 5, 10),\n",
        "    (8, 3, 1),\n",
        "]\n",
        "\n",
        "\n",
        "# Define schema for DataFrames\n",
        "product_columns = [\"ProductID\", \"ProductName\", \"Category\", \"Price\"]\n",
        "sales_columns = [\"SaleID\", \"ProductID\", \"Quantity\"]\n",
        "\n",
        "# Create DataFrames\n",
        "product_df = spark.createDataFrame(products, schema=product_columns)\n",
        "sales_df = spark.createDataFrame(sales, schema=sales_columns)\n",
        "\n",
        "# Show the DataFrames\n",
        "print(\"Products DataFrame:\")\n",
        "product_df.show()\n",
        "\n",
        "print(\"Sales DataFrame:\")\n",
        "sales_df.show()\n",
        "\n",
        "# 1. **Join the DataFrames:**\n",
        "#    - Join the `product_df` and `sales_df` DataFrames on `ProductID` to create a combined DataFrame with product and sales data.\n",
        "combined_df = sales_df.join(product_df, on=\"ProductID\", how=\"inner\")\n",
        "print(\"Combined DataFrame (Products + Sales):\")\n",
        "combined_df.show()\n",
        "\n",
        "\n",
        "# 2. **Calculate Total Sales Value:**\n",
        "#    - For each product, calculate the total sales value by multiplying the price by the quantity sold.\n",
        "combined_df = combined_df.withColumn(\"TotalSalesValue\", col(\"Price\") * col(\"Quantity\"))\n",
        "print(\"DataFrame with Total Sales Value:\")\n",
        "combined_df.show()\n",
        "\n",
        "# 3. **Find the Total Sales for Each Product Category:**\n",
        "#    - Group the data by the `Category` column and calculate the total sales value for each product category.\n",
        "category_sales_df = combined_df.groupBy(\"Category\").sum(\"TotalSalesValue\").withColumnRenamed(\"sum(TotalSalesValue)\",\"TotalCategorySales\")\n",
        "print(\"Total Sales for Each Product Category:\")\n",
        "category_sales_df.show()\n",
        "\n",
        "\n",
        "# 4. **Identify the Top-Selling Product:**\n",
        "#    - Find the product that generated the highest total sales value.\n",
        "top_selling_product_df = combined_df.groupBy(\"ProductID\", \"ProductName\").sum(\"TotalSalesValue\").withColumnRenamed(\"sum(TotalSalesValue)\",\"TotalSalesValue\")\n",
        "top_selling_product_df = top_selling_product_df.orderBy(col(\"TotalSalesValue\").desc())\n",
        "print(\"Top-Selling Product:\")\n",
        "top_selling_product_df.show(1)\n",
        "\n",
        "\n",
        "# 5. **Sort the Products by Total Sales Value:**\n",
        "#    - Sort the products by total sales value in descending order.\n",
        "sorted_products_df = top_selling_product_df.orderBy(col(\"TotalSalesValue\").desc())\n",
        "print(\"Products Sorted by Total Sales Value:\")\n",
        "sorted_products_df.show()\n",
        "\n",
        "\n",
        "# 6. **Count the Number of Sales for Each Product:**\n",
        "#    - Count the number of sales transactions for each product.\n",
        "sales_count_df = combined_df.groupBy(\"ProductID\", \"ProductName\").count().withColumnRenamed(\"count()\",\"NumberOfSales\")\n",
        "print(\"Number of Sales for Each Product:\")\n",
        "sales_count_df.show()\n",
        "\n",
        "\n",
        "# 7. **Filter the Products with Total Sales Value Greater Than ₹50,000:**\n",
        "#    - Filter out the products that have a total sales value greater than ₹50,000.\n",
        "high_sales_df = top_selling_product_df.filter(col(\"TotalSalesValue\") > 50000)\n",
        "print(\"Products with Total Sales Value Greater Than ₹50,000:\")\n",
        "high_sales_df.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYMczvnlVa2Z",
        "outputId": "e0786052-7348-4db3-fc1e-316570e7c1f5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Products DataFrame:\n",
            "+---------+-----------+-----------+-----+\n",
            "|ProductID|ProductName|   Category|Price|\n",
            "+---------+-----------+-----------+-----+\n",
            "|        1|     Laptop|Electronics|50000|\n",
            "|        2| Smartphone|Electronics|30000|\n",
            "|        3|      Table|  Furniture|15000|\n",
            "|        4|      Chair|  Furniture| 5000|\n",
            "|        5| Headphones|Electronics| 2000|\n",
            "+---------+-----------+-----------+-----+\n",
            "\n",
            "Sales DataFrame:\n",
            "+------+---------+--------+\n",
            "|SaleID|ProductID|Quantity|\n",
            "+------+---------+--------+\n",
            "|     1|        1|       2|\n",
            "|     2|        2|       1|\n",
            "|     3|        3|       3|\n",
            "|     4|        1|       1|\n",
            "|     5|        4|       5|\n",
            "|     6|        2|       2|\n",
            "|     7|        5|      10|\n",
            "|     8|        3|       1|\n",
            "+------+---------+--------+\n",
            "\n",
            "Combined DataFrame (Products + Sales):\n",
            "+---------+------+--------+-----------+-----------+-----+\n",
            "|ProductID|SaleID|Quantity|ProductName|   Category|Price|\n",
            "+---------+------+--------+-----------+-----------+-----+\n",
            "|        1|     1|       2|     Laptop|Electronics|50000|\n",
            "|        1|     4|       1|     Laptop|Electronics|50000|\n",
            "|        2|     2|       1| Smartphone|Electronics|30000|\n",
            "|        2|     6|       2| Smartphone|Electronics|30000|\n",
            "|        3|     3|       3|      Table|  Furniture|15000|\n",
            "|        3|     8|       1|      Table|  Furniture|15000|\n",
            "|        4|     5|       5|      Chair|  Furniture| 5000|\n",
            "|        5|     7|      10| Headphones|Electronics| 2000|\n",
            "+---------+------+--------+-----------+-----------+-----+\n",
            "\n",
            "DataFrame with Total Sales Value:\n",
            "+---------+------+--------+-----------+-----------+-----+---------------+\n",
            "|ProductID|SaleID|Quantity|ProductName|   Category|Price|TotalSalesValue|\n",
            "+---------+------+--------+-----------+-----------+-----+---------------+\n",
            "|        1|     1|       2|     Laptop|Electronics|50000|         100000|\n",
            "|        1|     4|       1|     Laptop|Electronics|50000|          50000|\n",
            "|        2|     2|       1| Smartphone|Electronics|30000|          30000|\n",
            "|        2|     6|       2| Smartphone|Electronics|30000|          60000|\n",
            "|        3|     3|       3|      Table|  Furniture|15000|          45000|\n",
            "|        3|     8|       1|      Table|  Furniture|15000|          15000|\n",
            "|        4|     5|       5|      Chair|  Furniture| 5000|          25000|\n",
            "|        5|     7|      10| Headphones|Electronics| 2000|          20000|\n",
            "+---------+------+--------+-----------+-----------+-----+---------------+\n",
            "\n",
            "Total Sales for Each Product Category:\n",
            "+-----------+------------------+\n",
            "|   Category|TotalCategorySales|\n",
            "+-----------+------------------+\n",
            "|Electronics|            260000|\n",
            "|  Furniture|             85000|\n",
            "+-----------+------------------+\n",
            "\n",
            "Top-Selling Product:\n",
            "+---------+-----------+---------------+\n",
            "|ProductID|ProductName|TotalSalesValue|\n",
            "+---------+-----------+---------------+\n",
            "|        1|     Laptop|         150000|\n",
            "+---------+-----------+---------------+\n",
            "only showing top 1 row\n",
            "\n",
            "Products Sorted by Total Sales Value:\n",
            "+---------+-----------+---------------+\n",
            "|ProductID|ProductName|TotalSalesValue|\n",
            "+---------+-----------+---------------+\n",
            "|        1|     Laptop|         150000|\n",
            "|        2| Smartphone|          90000|\n",
            "|        3|      Table|          60000|\n",
            "|        4|      Chair|          25000|\n",
            "|        5| Headphones|          20000|\n",
            "+---------+-----------+---------------+\n",
            "\n",
            "Number of Sales for Each Product:\n",
            "+---------+-----------+-----+\n",
            "|ProductID|ProductName|count|\n",
            "+---------+-----------+-----+\n",
            "|        1|     Laptop|    2|\n",
            "|        2| Smartphone|    2|\n",
            "|        3|      Table|    2|\n",
            "|        4|      Chair|    1|\n",
            "|        5| Headphones|    1|\n",
            "+---------+-----------+-----+\n",
            "\n",
            "Products with Total Sales Value Greater Than ₹50,000:\n",
            "+---------+-----------+---------------+\n",
            "|ProductID|ProductName|TotalSalesValue|\n",
            "+---------+-----------+---------------+\n",
            "|        1|     Laptop|         150000|\n",
            "|        2| Smartphone|          90000|\n",
            "|        3|      Table|          60000|\n",
            "+---------+-----------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8paOGG0IaCQI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}