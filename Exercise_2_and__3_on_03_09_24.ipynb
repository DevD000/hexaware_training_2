{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNw3/Xv5y3Cs21A/RMPDBux",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DevD000/hexaware_training_2/blob/main/Exercise_2_and__3_on_03_09_24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCozfzgXmr9e",
        "outputId": "af221b49-0533-4ac2-a3b6-edef9852a6b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample sales dataset has been created and saved as 'sales_data.csv'.\n"
          ]
        }
      ],
      "source": [
        "### **Exercise: Analyzing a Sample Sales Dataset Using PySpark**\n",
        "### **Part 1: Dataset Preparation**\n",
        "\n",
        "#### **Step 1: Generate the Sample Sales Dataset**\n",
        "\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Sample sales data\n",
        "data = {\n",
        "    \"TransactionID\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    \"CustomerID\": [101, 102, 103, 101, 104, 102, 103, 104, 101, 105],\n",
        "    \"ProductID\": [501, 502, 501, 503, 504, 502, 503, 504, 501, 505],\n",
        "    \"Quantity\": [2, 1, 4, 3, 1, 2, 5, 1, 2, 1],\n",
        "    \"Price\": [150.0, 250.0, 150.0, 300.0, 450.0, 250.0, 300.0, 450.0, 150.0, 550.0],\n",
        "    \"Date\": [\n",
        "        datetime(2024, 9, 1),\n",
        "        datetime(2024, 9, 1),\n",
        "        datetime(2024, 9, 2),\n",
        "        datetime(2024, 9, 2),\n",
        "        datetime(2024, 9, 3),\n",
        "        datetime(2024, 9, 3),\n",
        "        datetime(2024, 9, 4),\n",
        "        datetime(2024, 9, 4),\n",
        "        datetime(2024, 9, 5),\n",
        "        datetime(2024, 9, 5)\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('sales_data.csv', index=False)\n",
        "\n",
        "print(\"Sample sales dataset has been created and saved as 'sales_data.csv'.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zI1NfBxsslx",
        "outputId": "7804ec9d-c4c0-4094-8a28-7cc6c2ac1922"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=3ed001f0c0b1e98bf3e171230c79349c0ad546fae7d517a386ebbdad9b9ed0b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Sales Dataset Analysis\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "    # Load the sales dataset\n",
        "sales_df = spark.read.csv(\"sales_data.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Show the first few rows of the DataFrame\n",
        "sales_df.show()\n",
        "\n",
        "# Display the schema of the DataFrame\n",
        "sales_df.printSchema()\n",
        "\n",
        "# Display the first 5 rows of the DataFrame\n",
        "sales_df.show(5)\n",
        "\n",
        "# Get summary statistics for numeric columns (Quantity and Price)\n",
        "sales_df.describe([\"Quantity\", \"Price\"]).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpMWVADZsJ2H",
        "outputId": "cc5bac38-1829-4f4b-92b9-fc2ff40bd688"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+---------+--------+-----+----------+\n",
            "|TransactionID|CustomerID|ProductID|Quantity|Price|      Date|\n",
            "+-------------+----------+---------+--------+-----+----------+\n",
            "|            1|       101|      501|       2|150.0|2024-09-01|\n",
            "|            2|       102|      502|       1|250.0|2024-09-01|\n",
            "|            3|       103|      501|       4|150.0|2024-09-02|\n",
            "|            4|       101|      503|       3|300.0|2024-09-02|\n",
            "|            5|       104|      504|       1|450.0|2024-09-03|\n",
            "|            6|       102|      502|       2|250.0|2024-09-03|\n",
            "|            7|       103|      503|       5|300.0|2024-09-04|\n",
            "|            8|       104|      504|       1|450.0|2024-09-04|\n",
            "|            9|       101|      501|       2|150.0|2024-09-05|\n",
            "|           10|       105|      505|       1|550.0|2024-09-05|\n",
            "+-------------+----------+---------+--------+-----+----------+\n",
            "\n",
            "root\n",
            " |-- TransactionID: integer (nullable = true)\n",
            " |-- CustomerID: integer (nullable = true)\n",
            " |-- ProductID: integer (nullable = true)\n",
            " |-- Quantity: integer (nullable = true)\n",
            " |-- Price: double (nullable = true)\n",
            " |-- Date: date (nullable = true)\n",
            "\n",
            "+-------------+----------+---------+--------+-----+----------+\n",
            "|TransactionID|CustomerID|ProductID|Quantity|Price|      Date|\n",
            "+-------------+----------+---------+--------+-----+----------+\n",
            "|            1|       101|      501|       2|150.0|2024-09-01|\n",
            "|            2|       102|      502|       1|250.0|2024-09-01|\n",
            "|            3|       103|      501|       4|150.0|2024-09-02|\n",
            "|            4|       101|      503|       3|300.0|2024-09-02|\n",
            "|            5|       104|      504|       1|450.0|2024-09-03|\n",
            "+-------------+----------+---------+--------+-----+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-------+-----------------+-----------------+\n",
            "|summary|         Quantity|            Price|\n",
            "+-------+-----------------+-----------------+\n",
            "|  count|               10|               10|\n",
            "|   mean|              2.2|            300.0|\n",
            "| stddev|1.398411797560202|141.4213562373095|\n",
            "|    min|                1|            150.0|\n",
            "|    max|                5|            550.0|\n",
            "+-------+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Add a new column for TotalSales (Quantity * Price)\n",
        "sales_df = sales_df.withColumn(\"TotalSales\", col(\"Quantity\") * col(\"Price\"))\n",
        "\n",
        "# Show the updated DataFrame\n",
        "sales_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuo1olBKtLT9",
        "outputId": "27a73561-b08a-4945-b161-fe45b2091f9a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+---------+--------+-----+----------+----------+\n",
            "|TransactionID|CustomerID|ProductID|Quantity|Price|      Date|TotalSales|\n",
            "+-------------+----------+---------+--------+-----+----------+----------+\n",
            "|            1|       101|      501|       2|150.0|2024-09-01|     300.0|\n",
            "|            2|       102|      502|       1|250.0|2024-09-01|     250.0|\n",
            "|            3|       103|      501|       4|150.0|2024-09-02|     600.0|\n",
            "|            4|       101|      503|       3|300.0|2024-09-02|     900.0|\n",
            "|            5|       104|      504|       1|450.0|2024-09-03|     450.0|\n",
            "|            6|       102|      502|       2|250.0|2024-09-03|     500.0|\n",
            "|            7|       103|      503|       5|300.0|2024-09-04|    1500.0|\n",
            "|            8|       104|      504|       1|450.0|2024-09-04|     450.0|\n",
            "|            9|       101|      501|       2|150.0|2024-09-05|     300.0|\n",
            "|           10|       105|      505|       1|550.0|2024-09-05|     550.0|\n",
            "+-------------+----------+---------+--------+-----+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Group by ProductID and calculate total sales for each product\n",
        "product_sales_df = sales_df.groupBy(\"ProductID\").sum(\"TotalSales\").withColumnRenamed(\"sum(TotalSales)\",\"TotalProductSales\")\n",
        "\n",
        "# Show the result\n",
        "product_sales_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxEns41vvGQb",
        "outputId": "09a0411f-0bcf-427f-d0c7-0efa94247fa1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------------+\n",
            "|ProductID|TotalProductSales|\n",
            "+---------+-----------------+\n",
            "|      501|           1200.0|\n",
            "|      504|            900.0|\n",
            "|      502|            750.0|\n",
            "|      505|            550.0|\n",
            "|      503|           2400.0|\n",
            "+---------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the product with the highest total sales\n",
        "top_selling_product_df = product_sales_df.orderBy(col(\"TotalProductSales\").desc())\n",
        "\n",
        "# Show the top-selling product\n",
        "top_selling_product_df.show(1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjDggrnh2mYo",
        "outputId": "743b1f9f-46f6-473d-866a-1d4387a914d0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------------+\n",
            "|ProductID|TotalProductSales|\n",
            "+---------+-----------------+\n",
            "|      503|           2400.0|\n",
            "+---------+-----------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by Date and calculate total sales for each day\n",
        "daily_sales_df = sales_df.groupBy(\"Date\").sum(\"TotalSales\").withColumnRenamed(\"sum(TotalSales)\",\"TotalDailySales\")\n",
        "\n",
        "# Show the result\n",
        "daily_sales_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnbvZF-E2oEx",
        "outputId": "2bca3cc6-5508-4afc-c1dd-eaee66c14c8c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------------+\n",
            "|      Date|TotalDailySales|\n",
            "+----------+---------------+\n",
            "|2024-09-03|          950.0|\n",
            "|2024-09-01|          550.0|\n",
            "|2024-09-02|         1500.0|\n",
            "|2024-09-05|          850.0|\n",
            "|2024-09-04|         1950.0|\n",
            "+----------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter transactions with TotalSales greater than ₹500\n",
        "high_value_sales_df = sales_df.filter(col(\"TotalSales\") > 500)\n",
        "\n",
        "# Show the filtered transactions\n",
        "high_value_sales_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oj45EfWA2unE",
        "outputId": "f6644fba-3b40-4bb7-e611-166546e20d9d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+---------+--------+-----+----------+----------+\n",
            "|TransactionID|CustomerID|ProductID|Quantity|Price|      Date|TotalSales|\n",
            "+-------------+----------+---------+--------+-----+----------+----------+\n",
            "|            3|       103|      501|       4|150.0|2024-09-02|     600.0|\n",
            "|            4|       101|      503|       3|300.0|2024-09-02|     900.0|\n",
            "|            7|       103|      503|       5|300.0|2024-09-04|    1500.0|\n",
            "|           10|       105|      505|       1|550.0|2024-09-05|     550.0|\n",
            "+-------------+----------+---------+--------+-----+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of purchases made by each customer\n",
        "repeat_customers_df = sales_df.groupBy(\"CustomerID\").count().filter(col(\"count\") > 1)\n",
        "\n",
        "# Show repeat customers\n",
        "repeat_customers_df.show()\n",
        "\n",
        "# Calculate the average price per product\n",
        "avg_price_per_product_df = sales_df.groupBy(\"ProductID\").agg(sum(\"TotalSales\") / sum(\"Quantity\"))\n",
        "\n",
        "# Show the average price per product\n",
        "avg_price_per_product_df.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "jGF-btlq2u9f",
        "outputId": "7b4461cf-84a1-4b8a-c3ef-266aa4cd6727"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|CustomerID|count|\n",
            "+----------+-----+\n",
            "|       101|    3|\n",
            "|       103|    2|\n",
            "|       102|    2|\n",
            "|       104|    2|\n",
            "+----------+-----+\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-bc13e92d6075>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Calculate the average price per product\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mavg_price_per_product_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msales_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ProductID\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TotalSales\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Quantity\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Show the average price per product\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Key-Value Pair RDDs Exercise\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Get the SparkContext from SparkSession\n",
        "sc = spark.sparkContext\n",
        "\n",
        "#Task 1: Create an RDD from the Sales Data\n",
        "sales_data = [\n",
        "    (\"ProductA\", 100),\n",
        "    (\"ProductB\", 150),\n",
        "    (\"ProductA\", 200),\n",
        "    (\"ProductC\", 300),\n",
        "    (\"ProductB\", 250),\n",
        "    (\"ProductC\", 100)\n",
        "]\n",
        "\n",
        "# Create an RDD from sales_data\n",
        "sales_rdd = sc.parallelize(sales_data)\n",
        "\n",
        "\n",
        "print(\"Sales RDD:\")\n",
        "print(sales_rdd.take(5))\n",
        "\n",
        "#Task 2: Group Data by Product Name\n",
        "\n",
        "grouped_rdd = sales_rdd.groupByKey()\n",
        "\n",
        "\n",
        "print(\"Grouped Data:\")\n",
        "for product, sales in grouped_rdd.collect():\n",
        "    print(product, list(sales))\n",
        "\n",
        "\n",
        "#Task 3: Calculate Total Sales by Product\n",
        "# Calculate total sales for each product using reduceByKey\n",
        "total_sales_rdd = sales_rdd.reduceByKey(lambda x, y: x + y)\n",
        "\n",
        "\n",
        "print(\"Total Sales by Product:\")\n",
        "total_sales_rdd.collect()\n",
        "\n",
        "\n",
        "#Task 4: Sort Products by Total Sales\n",
        "sorted_sales_rdd = total_sales_rdd.sortBy(lambda x: x[1], ascending=False)\n",
        "\n",
        "\n",
        "print(\"Sorted Products by Total Sales:\")\n",
        "sorted_sales_rdd.collect()\n",
        "\n",
        "\n",
        "#Task 5: Filter Products with High Sales\n",
        "# Filter products with total sales greater than 200\n",
        "high_sales_rdd = total_sales_rdd.filter(lambda x: x[1] > 200)\n",
        "\n",
        "\n",
        "print(\"Products with Sales Greater Than 200:\")\n",
        "high_sales_rdd.collect()\n",
        "\n",
        "\n",
        "#Task 6: Combine Regional Sales Data\n",
        "\n",
        "# Regional sales data\n",
        "regional_sales_data = [\n",
        "    (\"ProductA\", 50),\n",
        "    (\"ProductC\", 150)\n",
        "]\n",
        "\n",
        "# Create an RDD from regional_sales_data\n",
        "regional_sales_rdd = sc.parallelize(regional_sales_data)\n",
        "\n",
        "# Combine the sales RDDs using union\n",
        "combined_rdd = sales_rdd.union(regional_sales_rdd)\n",
        "\n",
        "# Calculate the new total sales for each product after combining the datasets\n",
        "combined_total_sales_rdd = combined_rdd.reduceByKey(lambda x, y: x + y)\n",
        "\n",
        "\n",
        "print(\"Combined Sales Data:\")\n",
        "combined_total_sales_rdd.collect()\n",
        "\n",
        "#Task 7: Count the Number of Distinct Products\n",
        "\n",
        "\n",
        "distinct_products_count = combined_total_sales_rdd.keys().distinct().count()\n",
        "\n",
        "print(\"Number of Distinct Products:\", distinct_products_count)\n",
        "\n",
        "\n",
        "#Task 8: Identify the Product with Maximum Sales\n",
        "# Find the product with the maximum total sales using reduce\n",
        "max_sales_product = combined_total_sales_rdd.reduce(lambda x, y: x if x[1] > y[1] else y)\n",
        "\n",
        "\n",
        "print(\"Product with Maximum Sales:\", max_sales_product)\n",
        "\n",
        "#Challenge Task\n",
        "\n",
        "# Calculate the total quantity sold for each product\n",
        "total_quantity_rdd = sales_rdd.mapValues(lambda x: 1).reduceByKey(lambda x, y: x + y)\n",
        "\n",
        "total_sales_quantity_rdd = total_sales_rdd.join(total_quantity_rdd)\n",
        "\n",
        "\n",
        "avg_sales_rdd = total_sales_quantity_rdd.mapValues(lambda x: x[0] / x[1])\n",
        "\n",
        "\n",
        "print(\"Average Sales per Product:\")\n",
        "avg_sales_rdd.collect()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPNaHnKPdQut",
        "outputId": "816ec82e-7ae7-449b-c2a1-a3e1ab62ec9d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sales RDD:\n",
            "[('ProductA', 100), ('ProductB', 150), ('ProductA', 200), ('ProductC', 300), ('ProductB', 250)]\n",
            "Grouped Data:\n",
            "ProductA [100, 200]\n",
            "ProductB [150, 250]\n",
            "ProductC [300, 100]\n",
            "Total Sales by Product:\n",
            "Sorted Products by Total Sales:\n",
            "Products with Sales Greater Than 200:\n",
            "Combined Sales Data:\n",
            "Number of Distinct Products: 3\n",
            "Product with Maximum Sales: ('ProductC', 550)\n",
            "Average Sales per Product:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ProductA', 150.0), ('ProductB', 200.0), ('ProductC', 200.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fcz10CosdQoU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}